"""
Sistema de Recupera√ß√£o de Desastres e Alta Disponibilidade para Sankofa Enterprise Pro
Implementa failover autom√°tico, backup multi-regi√£o e estrat√©gias de continuidade de neg√≥cios
"""

import os
import json
import time
import logging
import datetime
import threading
import subprocess
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import psutil
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ServiceHealth:
    """Status de sa√∫de de um servi√ßo"""
    service_name: str
    status: str  # 'healthy', 'degraded', 'unhealthy', 'unknown'
    response_time_ms: float
    last_check: datetime.datetime
    error_message: Optional[str] = None
    uptime_percentage: float = 100.0

@dataclass
class BackupInfo:
    """Informa√ß√µes sobre um backup"""
    backup_id: str
    backup_type: str  # 'full', 'incremental', 'differential'
    created_at: datetime.datetime
    size_bytes: int
    location: str
    checksum: str
    status: str  # 'in_progress', 'completed', 'failed'

@dataclass
class FailoverEvent:
    """Evento de failover"""
    event_id: str
    trigger_reason: str
    source_service: str
    target_service: str
    started_at: datetime.datetime
    completed_at: Optional[datetime.datetime]
    status: str  # 'in_progress', 'completed', 'failed'
    rollback_plan: Dict[str, Any]

class DisasterRecoverySystem:
    """
    Sistema completo de recupera√ß√£o de desastres e alta disponibilidade
    """
    
    def __init__(self, config_path: str = "/home/ubuntu/sankofa-enterprise-real/config/dr_config.json"):
        self.config_path = Path(config_path)
        self.config_path.parent.mkdir(exist_ok=True)
        
        # Carrega configura√ß√µes
        self.config = self._load_config()
        
        # Estado do sistema
        self.service_health = {}
        self.backup_history = []
        self.failover_history = []
        
        # Controle de threads
        self.monitoring_active = False
        self.monitoring_thread = None
        
        # Diret√≥rios
        self.backup_dir = Path(self.config['backup']['local_path'])
        self.backup_dir.mkdir(exist_ok=True)
        
        logger.info("Sistema de Recupera√ß√£o de Desastres inicializado")
    
    def _load_config(self) -> Dict[str, Any]:
        """Carrega configura√ß√µes do sistema DR"""
        default_config = {
            "services": {
                "api_backend": {
                    "url": "https://localhost:8445/health",
                    "timeout": 5,
                    "critical": True,
                    "failover_target": "api_backend_backup"
                },
                "frontend": {
                    "url": "http://localhost:5174",
                    "timeout": 3,
                    "critical": True,
                    "failover_target": "frontend_backup"
                },
                "redis_cache": {
                    "url": "redis://localhost:6379",
                    "timeout": 2,
                    "critical": False,
                    "failover_target": "redis_backup"
                }
            },
            "monitoring": {
                "check_interval_seconds": 30,
                "failure_threshold": 3,
                "recovery_threshold": 2,
                "alert_webhook": None
            },
            "backup": {
                "local_path": "/home/ubuntu/sankofa-enterprise-real/backups",
                "remote_locations": [
                    "s3://sankofa-backups-primary/",
                    "s3://sankofa-backups-secondary/"
                ],
                "schedule": {
                    "full_backup_cron": "0 2 * * 0",  # Domingo √†s 2h
                    "incremental_backup_cron": "0 2 * * 1-6",  # Segunda a s√°bado √†s 2h
                    "retention_days": 30
                }
            },
            "failover": {
                "auto_failover_enabled": True,
                "failover_timeout_seconds": 300,
                "rollback_timeout_seconds": 600,
                "notification_channels": ["email", "slack"]
            },
            "regions": {
                "primary": "us-east-1",
                "secondary": "us-west-2",
                "tertiary": "eu-west-1"
            }
        }
        
        if self.config_path.exists():
            with open(self.config_path, 'r') as f:
                config = json.load(f)
        else:
            config = default_config
            with open(self.config_path, 'w') as f:
                json.dump(config, f, indent=2)
        
        return config
    
    def start_monitoring(self):
        """Inicia monitoramento cont√≠nuo dos servi√ßos"""
        if self.monitoring_active:
            logger.warning("Monitoramento j√° est√° ativo")
            return
        
        self.monitoring_active = True
        self.monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitoring_thread.start()
        
        logger.info("Monitoramento de alta disponibilidade iniciado")
    
    def stop_monitoring(self):
        """Para o monitoramento"""
        self.monitoring_active = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        
        logger.info("Monitoramento parado")
    
    def _monitoring_loop(self):
        """Loop principal de monitoramento"""
        while self.monitoring_active:
            try:
                self._check_all_services()
                self._evaluate_failover_conditions()
                time.sleep(self.config['monitoring']['check_interval_seconds'])
            except Exception as e:
                logger.error(f"Erro no loop de monitoramento: {e}")
                time.sleep(10)  # Espera mais tempo em caso de erro
    
    def _check_all_services(self):
        """Verifica sa√∫de de todos os servi√ßos"""
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = {
                executor.submit(self._check_service_health, name, config): name
                for name, config in self.config['services'].items()
            }
            
            for future in as_completed(futures):
                service_name = futures[future]
                try:
                    health = future.result()
                    self.service_health[service_name] = health
                except Exception as e:
                    logger.error(f"Erro ao verificar servi√ßo {service_name}: {e}")
                    self.service_health[service_name] = ServiceHealth(
                        service_name=service_name,
                        status='unknown',
                        response_time_ms=0,
                        last_check=datetime.datetime.now(),
                        error_message=str(e)
                    )
    
    def _check_service_health(self, service_name: str, service_config: Dict[str, Any]) -> ServiceHealth:
        """Verifica sa√∫de de um servi√ßo espec√≠fico"""
        start_time = time.time()
        
        try:
            if service_config['url'].startswith('http'):
                # Verifica√ß√£o HTTP
                response = requests.get(
                    service_config['url'],
                    timeout=service_config['timeout'],
                    verify=False  # Para HTTPS auto-assinado
                )
                
                response_time = (time.time() - start_time) * 1000
                
                if response.status_code == 200:
                    status = 'healthy'
                    error_message = None
                elif response.status_code < 500:
                    status = 'degraded'
                    error_message = f"HTTP {response.status_code}"
                else:
                    status = 'unhealthy'
                    error_message = f"HTTP {response.status_code}"
                
            elif service_config['url'].startswith('redis'):
                # Verifica√ß√£o Redis
                import redis
                r = redis.from_url(service_config['url'])
                r.ping()
                
                response_time = (time.time() - start_time) * 1000
                status = 'healthy'
                error_message = None
                
            else:
                # Verifica√ß√£o gen√©rica de porta
                import socket
                host, port = service_config['url'].split(':')
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.settimeout(service_config['timeout'])
                result = sock.connect_ex((host, int(port)))
                sock.close()
                
                response_time = (time.time() - start_time) * 1000
                
                if result == 0:
                    status = 'healthy'
                    error_message = None
                else:
                    status = 'unhealthy'
                    error_message = f"Connection failed to {host}:{port}"
        
        except Exception as e:
            response_time = (time.time() - start_time) * 1000
            status = 'unhealthy'
            error_message = str(e)
        
        return ServiceHealth(
            service_name=service_name,
            status=status,
            response_time_ms=response_time,
            last_check=datetime.datetime.now(),
            error_message=error_message
        )
    
    def _evaluate_failover_conditions(self):
        """Avalia se √© necess√°rio fazer failover"""
        if not self.config['failover']['auto_failover_enabled']:
            return
        
        for service_name, health in self.service_health.items():
            service_config = self.config['services'][service_name]
            
            # Verifica se √© um servi√ßo cr√≠tico e est√° unhealthy
            if service_config.get('critical', False) and health.status == 'unhealthy':
                # Verifica hist√≥rico de falhas
                recent_failures = self._count_recent_failures(service_name)
                
                if recent_failures >= self.config['monitoring']['failure_threshold']:
                    logger.warning(f"Servi√ßo {service_name} atingiu threshold de falhas. Iniciando failover...")
                    self._initiate_failover(service_name)
    
    def _count_recent_failures(self, service_name: str) -> int:
        """Conta falhas recentes de um servi√ßo"""
        # Implementa√ß√£o simplificada - em produ√ß√£o seria mais sofisticada
        health = self.service_health.get(service_name)
        if health and health.status == 'unhealthy':
            return 3  # Simula threshold atingido
        return 0
    
    def _initiate_failover(self, service_name: str):
        """Inicia processo de failover para um servi√ßo"""
        service_config = self.config['services'][service_name]
        target_service = service_config.get('failover_target')
        
        if not target_service:
            logger.error(f"Nenhum target de failover configurado para {service_name}")
            return
        
        event_id = f"failover_{service_name}_{int(time.time())}"
        
        failover_event = FailoverEvent(
            event_id=event_id,
            trigger_reason="Service health check failure",
            source_service=service_name,
            target_service=target_service,
            started_at=datetime.datetime.now(),
            completed_at=None,
            status='in_progress',
            rollback_plan={
                "original_service": service_name,
                "backup_config": service_config.copy()
            }
        )
        
        self.failover_history.append(failover_event)
        
        try:
            # Executa failover
            success = self._execute_failover(service_name, target_service)
            
            if success:
                failover_event.status = 'completed'
                failover_event.completed_at = datetime.datetime.now()
                logger.info(f"Failover conclu√≠do: {service_name} -> {target_service}")
                
                # Envia notifica√ß√£o
                self._send_failover_notification(failover_event)
            else:
                failover_event.status = 'failed'
                logger.error(f"Failover falhou: {service_name} -> {target_service}")
        
        except Exception as e:
            failover_event.status = 'failed'
            logger.error(f"Erro durante failover: {e}")
    
    def _execute_failover(self, source_service: str, target_service: str) -> bool:
        """Executa o failover propriamente dito"""
        logger.info(f"Executando failover: {source_service} -> {target_service}")
        
        # Implementa√ß√£o simplificada - em produ√ß√£o seria mais complexa
        try:
            # 1. Para servi√ßo com problema
            self._stop_service(source_service)
            
            # 2. Inicia servi√ßo backup
            self._start_service(target_service)
            
            # 3. Atualiza configura√ß√µes de roteamento
            self._update_routing_config(source_service, target_service)
            
            # 4. Verifica se failover foi bem-sucedido
            time.sleep(5)  # Aguarda estabiliza√ß√£o
            
            return self._verify_failover_success(target_service)
        
        except Exception as e:
            logger.error(f"Erro na execu√ß√£o do failover: {e}")
            return False
    
    def _stop_service(self, service_name: str):
        """Para um servi√ßo"""
        logger.info(f"Parando servi√ßo: {service_name}")
        # Implementa√ß√£o espec√≠fica para cada tipo de servi√ßo
        pass
    
    def _start_service(self, service_name: str):
        """Inicia um servi√ßo"""
        logger.info(f"Iniciando servi√ßo: {service_name}")
        # Implementa√ß√£o espec√≠fica para cada tipo de servi√ßo
        pass
    
    def _update_routing_config(self, source_service: str, target_service: str):
        """Atualiza configura√ß√µes de roteamento"""
        logger.info(f"Atualizando roteamento: {source_service} -> {target_service}")
        # Atualiza load balancer, DNS, etc.
        pass
    
    def _verify_failover_success(self, target_service: str) -> bool:
        """Verifica se o failover foi bem-sucedido"""
        # Tenta conectar ao servi√ßo backup
        try:
            # Implementa√ß√£o espec√≠fica de verifica√ß√£o
            return True
        except Exception:
            return False
    
    def _send_failover_notification(self, event: FailoverEvent):
        """Envia notifica√ß√£o sobre failover"""
        message = f"""
        üö® FAILOVER EXECUTADO
        
        Servi√ßo: {event.source_service} -> {event.target_service}
        Motivo: {event.trigger_reason}
        Hor√°rio: {event.started_at}
        Status: {event.status}
        """
        
        logger.info(f"Notifica√ß√£o de failover: {message}")
        # Implementar envio real (email, Slack, etc.)
    
    def create_backup(self, backup_type: str = 'incremental') -> BackupInfo:
        """Cria backup do sistema"""
        backup_id = f"backup_{backup_type}_{int(time.time())}"
        
        backup_info = BackupInfo(
            backup_id=backup_id,
            backup_type=backup_type,
            created_at=datetime.datetime.now(),
            size_bytes=0,
            location=str(self.backup_dir / f"{backup_id}.tar.gz"),
            checksum="",
            status='in_progress'
        )
        
        try:
            logger.info(f"Iniciando backup {backup_type}: {backup_id}")
            
            # Cria backup dos dados cr√≠ticos
            backup_path = self._create_system_backup(backup_type, backup_id)
            
            # Calcula checksum
            checksum = self._calculate_checksum(backup_path)
            
            # Atualiza informa√ß√µes
            backup_info.size_bytes = os.path.getsize(backup_path)
            backup_info.checksum = checksum
            backup_info.status = 'completed'
            
            # Replica para locais remotos
            self._replicate_backup(backup_path)
            
            self.backup_history.append(backup_info)
            
            logger.info(f"Backup conclu√≠do: {backup_id}")
            
        except Exception as e:
            backup_info.status = 'failed'
            logger.error(f"Erro no backup: {e}")
        
        return backup_info
    
    def _create_system_backup(self, backup_type: str, backup_id: str) -> str:
        """Cria backup f√≠sico do sistema"""
        backup_path = self.backup_dir / f"{backup_id}.tar.gz"
        
        # Diret√≥rios para backup
        backup_dirs = [
            "/home/ubuntu/sankofa-enterprise-real/backend",
            "/home/ubuntu/sankofa-enterprise-real/frontend",
            "/home/ubuntu/sankofa-enterprise-real/models",
            "/home/ubuntu/sankofa-enterprise-real/config",
            "/home/ubuntu/sankofa-enterprise-real/logs"
        ]
        
        # Cria arquivo tar
        import tarfile
        with tarfile.open(backup_path, 'w:gz') as tar:
            for dir_path in backup_dirs:
                if os.path.exists(dir_path):
                    tar.add(dir_path, arcname=os.path.basename(dir_path))
        
        return str(backup_path)
    
    def _calculate_checksum(self, file_path: str) -> str:
        """Calcula checksum MD5 do arquivo"""
        import hashlib
        
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        
        return hash_md5.hexdigest()
    
    def _replicate_backup(self, backup_path: str):
        """Replica backup para locais remotos"""
        for remote_location in self.config['backup']['remote_locations']:
            try:
                logger.info(f"Replicando backup para: {remote_location}")
                # Implementar upload para S3, etc.
                # aws s3 cp backup_path remote_location
            except Exception as e:
                logger.error(f"Erro na replica√ß√£o para {remote_location}: {e}")
    
    def restore_from_backup(self, backup_id: str) -> bool:
        """Restaura sistema a partir de backup"""
        logger.info(f"Iniciando restaura√ß√£o do backup: {backup_id}")
        
        try:
            # Encontra backup
            backup_info = None
            for backup in self.backup_history:
                if backup.backup_id == backup_id:
                    backup_info = backup
                    break
            
            if not backup_info:
                logger.error(f"Backup {backup_id} n√£o encontrado")
                return False
            
            # Verifica integridade
            if not self._verify_backup_integrity(backup_info):
                logger.error(f"Backup {backup_id} falhou na verifica√ß√£o de integridade")
                return False
            
            # Para servi√ßos
            self._stop_all_services()
            
            # Restaura dados
            self._restore_backup_data(backup_info)
            
            # Reinicia servi√ßos
            self._start_all_services()
            
            logger.info(f"Restaura√ß√£o conclu√≠da: {backup_id}")
            return True
        
        except Exception as e:
            logger.error(f"Erro na restaura√ß√£o: {e}")
            return False
    
    def _verify_backup_integrity(self, backup_info: BackupInfo) -> bool:
        """Verifica integridade do backup"""
        if not os.path.exists(backup_info.location):
            return False
        
        # Verifica checksum
        current_checksum = self._calculate_checksum(backup_info.location)
        return current_checksum == backup_info.checksum
    
    def _restore_backup_data(self, backup_info: BackupInfo):
        """Restaura dados do backup"""
        import tarfile
        
        with tarfile.open(backup_info.location, 'r:gz') as tar:
            tar.extractall(path="/home/ubuntu/sankofa-enterprise-real/")
    
    def _stop_all_services(self):
        """Para todos os servi√ßos"""
        logger.info("Parando todos os servi√ßos...")
        # Implementar parada de servi√ßos
    
    def _start_all_services(self):
        """Inicia todos os servi√ßos"""
        logger.info("Iniciando todos os servi√ßos...")
        # Implementar in√≠cio de servi√ßos
    
    def get_system_status(self) -> Dict[str, Any]:
        """Retorna status completo do sistema"""
        return {
            "timestamp": datetime.datetime.now().isoformat(),
            "monitoring_active": self.monitoring_active,
            "services": {
                name: asdict(health) if health else None
                for name, health in self.service_health.items()
            },
            "recent_backups": [
                asdict(backup) for backup in self.backup_history[-5:]
            ],
            "recent_failovers": [
                asdict(event) for event in self.failover_history[-5:]
            ],
            "system_resources": {
                "cpu_percent": psutil.cpu_percent(),
                "memory_percent": psutil.virtual_memory().percent,
                "disk_percent": psutil.disk_usage('/').percent
            }
        }

def test_disaster_recovery_system():
    """
    Testa o sistema de recupera√ß√£o de desastres
    """
    print("üöÄ Testando Sistema de Recupera√ß√£o de Desastres...")
    
    # Inicializa sistema
    dr_system = DisasterRecoverySystem()
    
    # Inicia monitoramento
    dr_system.start_monitoring()
    
    # Aguarda algumas verifica√ß√µes
    time.sleep(5)
    
    # Cria backup
    backup_info = dr_system.create_backup('incremental')
    print(f"‚úÖ Backup criado: {backup_info.backup_id}")
    
    # Verifica status do sistema
    status = dr_system.get_system_status()
    print(f"‚úÖ Status do sistema obtido - Servi√ßos monitorados: {len(status['services'])}")
    
    # Para monitoramento
    dr_system.stop_monitoring()
    
    print("üéâ Teste do Sistema de Recupera√ß√£o de Desastres conclu√≠do!")
    
    return dr_system, backup_info

if __name__ == "__main__":
    test_disaster_recovery_system()
